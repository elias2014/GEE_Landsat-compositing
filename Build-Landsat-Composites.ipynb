{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wetland Change in the Chaco\n",
    "\n",
    "## Part 01: Create composites in Google Earth Engine and download\n",
    "\n",
    "##### (c) Matthias Baumann (with strong support by Julian Oeser)\n",
    "Initial script creation: 2018-08-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all other packages needed\n",
    "import os\n",
    "import re\n",
    "import baumiTools as bt\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and initialize Google Earth Engine\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script creates annual landsat composites in Google Earth Engine and downloads them onto a local disc.\n",
    "##### Step (1): Manually upload tile-scheme as feature collection into GEE, and load here as asset\n",
    "* Load as variable 'tiles'\n",
    "* the id-Field to be accessed is 'ID' or 'TileIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = ee.FeatureCollection('users/matthiasbaumann84/CHACO_tiles_v02')\n",
    "tilevar = 'Id'\n",
    "tile_names = tiles.distinct(tilevar).aggregate_array(tilevar).getInfo()\n",
    "features = ee.Feature(tiles.first()).propertyNames().sort()#.remove(response).remove('system:index').remove(tilevar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "localFolder = 'Z:/CHACO/_LANDSAT/annual_Metrics/1991/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step (2): Collect all Landsat T1 surface reflectance data for a given region and time period, calculate spectral indices.\n",
    "* apply masking (e.g., clouds) based on Pixel-QA band, \n",
    "* remove double observations from WRS path overlap areas,\n",
    "* harmonize Landsat 8 reflectance with Landsat 7 based on coefficients from Roy et al. 2016 (https://www.sciencedirect.com/science/article/pii/S0034425715302455, Table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landsat_collect (roi, \n",
    "                     start, \n",
    "                     end, \n",
    "                     seasonal_filter = ee.Filter.dayOfYear(1, 366),\n",
    "                     mask_clouds = True,\n",
    "                     mask_water = False,\n",
    "                     mask_snow = False,\n",
    "                     mask_fill = True,\n",
    "                     harmonize_l8 = True):\n",
    "    \n",
    "    select_bands = ['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2', 'pixel_qa']\n",
    "    # band names in input and output collections\n",
    "    bands = ['B1', 'B2', 'B3', 'B4', 'B5','B7', 'B6', 'pixel_qa']\n",
    "    band_names = ['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2', 'T','pixel_qa']\n",
    "    l8bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B1', 'B10', 'B11', 'pixel_qa']\n",
    "    l8band_names = ['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2', 'UB', 'T1', 'T2','pixel_qa']\n",
    "\n",
    "    # qa bits \n",
    "    cloudbit = ee.Number(ee.Algorithms.If(mask_clouds, 40, 0))\n",
    "    waterbit = ee.Number(ee.Algorithms.If(mask_water, 4, 0))\n",
    "    snowbit = ee.Number(ee.Algorithms.If(mask_snow, 16, 0))\n",
    "    fillbit = ee.Number(ee.Algorithms.If(mask_fill, 1, 0))\n",
    "    bits = cloudbit.add(waterbit).add(snowbit).add(fillbit)\n",
    "\n",
    "    ## helper functions\n",
    "    # function to apply masks based on pixel qa band\n",
    "    def apply_masks (img):\n",
    "        qa = img.select('pixel_qa')\n",
    "        mask = qa.bitwiseAnd(bits).eq(0)\n",
    "        return img.updateMask(mask)\n",
    "\n",
    "    # function to harmonize l8 surface reflectance with coefficients from Roy et al. 2016\n",
    "    def l8_harmonize (l8img):\n",
    "        b = ee.Image(0.0183).add(ee.Image(0.8850).multiply(l8img.select('B'))).int16()\n",
    "        g = ee.Image(0.0123).add(ee.Image(0.9317).multiply(l8img.select('G'))).int16()\n",
    "        r = ee.Image(0.0123).add(ee.Image(0.9372).multiply(l8img.select('R'))).int16()\n",
    "        nir = ee.Image(0.0448).add(ee.Image(0.8339).multiply(l8img.select('NIR'))).int16()\n",
    "        swir1 = ee.Image(0.0306).add(ee.Image(0.8639).multiply(l8img.select('SWIR1'))).int16()\n",
    "        swir2 = ee.Image(0.0116).add(ee.Image(0.9165).multiply(l8img.select('SWIR2'))).int16()\n",
    "\n",
    "        out = ee.Image(b.addBands(g).addBands(r).addBands(nir).addBands(swir1).addBands(swir2).addBands(l8img.select(['UB', 'T1', 'T2','pixel_qa'])).copyProperties(l8img, l8img.propertyNames())).rename(l8band_names)\n",
    "        return out\n",
    "    \n",
    "    # function to remove double counts from path overlap areas\n",
    "    def remove_double_counts (collection):\n",
    "        \n",
    "        def add_nn(image):\n",
    "            start = ee.Date.fromYMD(image.date().get('year'), image.date().get('month'), image.date().get('day')).update(hour = 0, minute = 0, second = 0)\n",
    "            end = ee.Date.fromYMD(image.date().get('year'), image.date().get('month'), image.date().get('day')).update(hour = 23, minute = 59, second = 59)\n",
    "            overlapping = collection.filterDate(start, end).filterBounds(image.geometry())\n",
    "            nn = overlapping.filterMetadata('WRS_ROW', 'equals', ee.Number(image.get('WRS_ROW')).subtract(1)).size()\n",
    "            return image.set('nn', nn)\n",
    "        \n",
    "        collection_nn = collection.map(add_nn)\n",
    "        has_nn = collection_nn.filterMetadata('nn', 'greater_than', 0)\n",
    "        has_no_nn = ee.ImageCollection(ee.Join.inverted().apply(collection, has_nn, ee.Filter.equals(leftField = 'LANDSAT_ID', rightField = 'LANDSAT_ID')))\n",
    "      \n",
    "        def mask_overlap(image):\n",
    "            start = ee.Date.fromYMD(image.date().get('year'), image.date().get('month'), image.date().get('day')).update(hour = 0, minute = 0, second = 0)\n",
    "            end = ee.Date.fromYMD(image.date().get('year'), image.date().get('month'), image.date().get('day')).update(hour = 23, minute = 59, second = 59)\n",
    "            overlapping = collection.filterDate(start, end).filterBounds(image.geometry())\n",
    "            nn = ee.Image(overlapping.filterMetadata('WRS_ROW', 'equals', ee.Number(image.get('WRS_ROW')).subtract(1)).first())\n",
    "            newmask = image.mask().where(nn.mask(), 0)\n",
    "            return image.updateMask(newmask)\n",
    "\n",
    "        has_nn_masked = ee.ImageCollection(has_nn.map(mask_overlap))\n",
    "        out = ee.ImageCollection(has_nn_masked.merge(has_no_nn).copyProperties(collection))\n",
    "        return out\n",
    "  \n",
    "    # get landsat data, apply filters and masks\n",
    "    l4 = remove_double_counts(ee.ImageCollection('LANDSAT/LT04/C01/T1_SR').select(bands, band_names).filterBounds(roi).filterDate(start, end).filter(seasonal_filter).map(apply_masks))\n",
    "    l5 = remove_double_counts(ee.ImageCollection('LANDSAT/LT05/C01/T1_SR').select(bands, band_names).filterBounds(roi).filterDate(start, end).filter(seasonal_filter).map(apply_masks))\n",
    "    l7 = remove_double_counts(ee.ImageCollection('LANDSAT/LE07/C01/T1_SR').select(bands, band_names).filterBounds(roi).filterDate(start, end).filter(seasonal_filter).map(apply_masks))\n",
    "    l8 = remove_double_counts(ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').select(l8bands, l8band_names).filterBounds(roi).filterDate(start, end).filter(seasonal_filter).map(apply_masks))\n",
    "    l8h = ee.ImageCollection(ee.Algorithms.If(harmonize_l8, l8.map(l8_harmonize), l8))\n",
    "\n",
    "    # combine landsat collections\n",
    "    landsat = ee.ImageCollection(l4.merge(l5).merge(l7).merge(l8h)).select(select_bands)\n",
    "    return landsat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* calculate  some additional spectral indices for the classification\n",
    "* For the tasseled cap transformation, also 'forurth', 'fifth' and 'sixth' component are calculated. for the download of the tile lateron not considered, though. can be done by commenting the resptive line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landsat_indices (landsat, indices):\n",
    "    \n",
    "    # helper functions to add spectral indices to collections\n",
    "    def add_NBR (image):\n",
    "        nbr = image.normalizedDifference(['NIR', 'SWIR2']).rename('NBR')\n",
    "        return image.addBands(nbr)\n",
    "    def add_NDMI (image):\n",
    "        ndvi = image.normalizedDifference(['NIR', 'SWIR1']).rename('NDMI')\n",
    "        return image.addBands(ndvi)\n",
    "    def add_EVI (image):\n",
    "        evi = image.expression('2.5 * ((NIR - R) / (NIR + 6 * R - 7.5 * B + 1))', {'NIR': image.select('NIR'),'R': image.select('R'),'B': image.select('B')}).rename('EVI')\n",
    "        return image.addBands(evi)\n",
    "    def add_MSAVI (image): \n",
    "        msavi = image.expression('(2 * NIR + 1 - sqrt(pow((2 * NIR + 1), 2) - 8 * (NIR - R)) ) / 2', {'NIR': image.select('NIR'),'R': image.select('R')}).rename('MSAVI')\n",
    "        return image.addBands(msavi)\n",
    "    def add_TC (image):\n",
    "        \n",
    "        img = image.select(['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "        # coefficients for Landsat surface reflectance (Crist 1985)\n",
    "        brightness_c= ee.Image([0.3037, 0.2793, 0.4743, 0.5585, 0.5082, 0.1863])\n",
    "        greenness_c= ee.Image([-0.2848, -0.2435, -0.5436, 0.7243, 0.0840, -0.1800])\n",
    "        wetness_c= ee.Image([0.1509, 0.1973, 0.3279, 0.3406, -0.7112, -0.4572])\n",
    "        fourth_c= ee.Image([-0.8242, 0.0849, 0.4392, -0.0580, 0.2012, -0.2768])\n",
    "        fifth_c= ee.Image([-0.3280, 0.0549, 0.1075, 0.1855, -0.4357, 0.8085])\n",
    "        sixth_c= ee.Image([0.1084, -0.9022, 0.4120, 0.0573, -0.0251, 0.0238])\n",
    "\n",
    "        brightness = img.multiply(brightness_c)\n",
    "        greenness = img.multiply(greenness_c)\n",
    "        wetness = img.multiply(wetness_c)\n",
    "        fourth = img.multiply(fourth_c)\n",
    "        fifth = img.multiply(fifth_c)\n",
    "        sixth = img.multiply(sixth_c)\n",
    "\n",
    "        brightness = brightness.reduce(ee.call('Reducer.sum'))\n",
    "        greenness = greenness.reduce(ee.call('Reducer.sum'))\n",
    "        wetness = wetness.reduce(ee.call('Reducer.sum'))\n",
    "        fourth = fourth.reduce(ee.call('Reducer.sum'))\n",
    "        fifth = fifth.reduce(ee.call('Reducer.sum'))\n",
    "        sixth = sixth.reduce(ee.call('Reducer.sum'))\n",
    "\n",
    "        tasseled_cap = ee.Image(brightness).addBands(greenness).addBands(wetness).rename(['brightness','greenness','wetness'])\n",
    "        #tasseled_cap = ee.Image(brightness).addBands(greenness).addBands(wetness).addBands(fourth).addBands(fifth).addBands(sixth)rename(['brightness','greenness','wetness', 'fourth', 'fifth', 'sixth']\n",
    "        return image.addBands(tasseled_cap)\n",
    "\n",
    "    out = landsat.map(add_NBR).map(add_NDMI).map(add_EVI).map(add_MSAVI).map(add_TC).select(indices)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step (3): Create composites\n",
    "* Build some helper functions.\n",
    "    * To stack the images and collections, when iterating over years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_images(image_list): \n",
    "    first = ee.Image(image_list.get(0)).select([])\n",
    "    \n",
    "    def add_img (image, previous):\n",
    "        return ee.Image(previous).addBands(image)\n",
    "    \n",
    "    return ee.Image(image_list.iterate(add_img, first))\n",
    "\n",
    "\n",
    "def stack_collection(collection):\n",
    "    first = ee.Image(collection.first()).select([])\n",
    "    \n",
    "    def add_img (image, previous):\n",
    "        return ee.Image(previous).addBands(image)\n",
    "    \n",
    "    return ee.Image(collection.iterate(add_img, first))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we build the function to generate the predictors per tile\n",
    "    * Mean, sd, median, 10/25/75/90 percentiles (in that exact order) of the six multispectral bands\n",
    "    * Mean, sd, median, 10/25/75/90 percentiles (in that exact order) of NBR, NDMI, EVI, MSAVI, TC_B, TC_G, TC_W\n",
    "* In the example below this can be done by determining a sequence of years (startYear/endYear)\n",
    "    * For the current project (i.e., downloading composites for large tiles) startYear = endYear\n",
    "    * Can be adjusted according to the needs\n",
    "* One can also decide which predictors to include\n",
    "    + Landsat spectral metrics only\n",
    "    + Index metrics only\n",
    "    + Landsat and index metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predictors_all(tile):\n",
    "    # define start year and end year for the compositing\n",
    "    startYear = 1991\n",
    "    endYear = 1991\n",
    "    years = ee.List.sequence(startYear, endYear)\n",
    "    \n",
    "    # Define some start specific values\n",
    "    roi = tiles.filterMetadata(tilevar, 'equals', tile)  \n",
    "    left = ee.Number(1)\n",
    "    right = ee.Number(1)\n",
    "    \n",
    "    def year_predictors(year):\n",
    "        # Define seasonal window --> here: entire year\n",
    "        start = ee.Date.fromYMD(ee.Number(year).subtract(ee.Number(1)), 1, 1)\n",
    "        end = ee.Date.fromYMD(ee.Number(year).add(ee.Number(1)), 12, 31)\n",
    "        start_window = ee.Date.fromYMD(ee.Number(year).subtract(left), 1, 1)\n",
    "        end_window = ee.Date.fromYMD(ee.Number(year).add(right), 12, 31)\n",
    "\n",
    "        # Collect the data\n",
    "        landsat_data = landsat_collect(roi, start_window, end_window).select(['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "        spectral_indices = landsat_indices(landsat_data, [\"NBR\", \"NDMI\", \"EVI\", \"MSAVI\", \"wetness\", \"brightness\", \"greenness\"])\n",
    "        \n",
    "        # Create the reducers\n",
    "        mean = ee.Reducer.mean().unweighted()\n",
    "        sd = ee.Reducer.stdDev().unweighted()\n",
    "        median = ee.Reducer.percentile([50]). unweighted()\n",
    "        percentiles = ee.Reducer.percentile([10,25,75,90]).unweighted()\n",
    "        #minmax = ee.Reducer.minMax().unweighted()\n",
    "        metrics_summary = mean.combine(sd, sharedInputs = True).combine(median, sharedInputs = True).combine(percentiles, sharedInputs= True)\n",
    "        \n",
    "        # Calculate the predictors\n",
    "        #predictors = landsat_data.reduce(metrics_summary)\n",
    "        #predictors = spectral_indices.reduce(metrics_summary)\n",
    "        predictors = landsat_data.reduce(metrics_summary).addBands(spectral_indices.reduce(metrics_summary))\n",
    "        return predictors.set('system:time_start', start.millis())\n",
    "    \n",
    "    predictor_year = years.map(year_predictors)\n",
    "    return ee.ImageCollection(predictor_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Helper-function to rename bands to short names. Needed, because if you use the full band names, you run into trouble when creating a .shp out of the exports (maximum variable name length)\n",
    "* not elegant, but the easiest workaround that i found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_bands(multiband):\n",
    "    old_bandnames = multiband.bandNames()\n",
    "    bandseq = ee.List.sequence(1, old_bandnames.size())\n",
    "    def create_bandnames(i):\n",
    "        return ee.String('v').cat(ee.Number(i).format('%03d'))\n",
    "    new_bandnames = bandseq.map(create_bandnames)\n",
    "    return multiband.select(old_bandnames, new_bandnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step (4): Export the composites to disc via google-drive\n",
    "* Build export-function.\n",
    "    * Convert values into integer values to safe space\n",
    "        * In case of using only Landsat metrics --> convert to int only\n",
    "        * In case of using Landsat and/or index metrics --> convert to int and multiply by 10000 (needs to be updated)\n",
    "    * Define folder, that you previously generated on your Google Drive\n",
    "        * Here: 'Baumi_GEE'\n",
    "* Check locally for existing processed tiles\n",
    "    * Cell needs to be re-run each time before starting the export. Otherwise, tiles are getting re-processed\n",
    "* Authenticate your google account\n",
    "    * infos on how to create the *client_secrets.py* file here: *https://pythonhosted.org/PyDrive/quickstart.html#authentication*\n",
    "    * then copy the file into the folder from where we execute the script\n",
    "* start the batch download to sequentially download the composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_composite(tile):\n",
    "  \n",
    "    roi = tiles.filterMetadata(tilevar, 'equals', tile)\n",
    "    #To safe space, multiply floating values by 10000\n",
    "    #tile_collection = stack_collection(calculate_predictors_all(tile).map(rename_bands)).int()\n",
    "    tile_collection = stack_collection(calculate_predictors_all(tile).map(rename_bands)).multiply(10000).int()\n",
    "\n",
    "    description = 'export_' + str(tile)\n",
    "    fileNamePrefix = 'tileID_' + str(tile)\n",
    "    GEE_Folder = 'Baumi_GEE'\n",
    "    \n",
    "    task= ee.batch.Export.image.toDrive(\n",
    "        image = tile_collection,\n",
    "        description = description,\n",
    "        folder = GEE_Folder,\n",
    "        fileNamePrefix = fileNamePrefix,\n",
    "        region = roi.geometry().getInfo()['coordinates'],\n",
    "        scale = 30)\n",
    "    \n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list =[]\n",
    "for file in os.listdir(localFolder):\n",
    "    if file.endswith(\".tif\"):\n",
    "        file_list.append(file)\n",
    "processed_tiles = []\n",
    "for filename in file_list:\n",
    "    result = re.search('\\d+', filename)\n",
    "    processed_tiles.append(result.group(0))\n",
    "missing_tiles = []\n",
    "for tile in tile_names:\n",
    "    t = str(tile)\n",
    "    if(t not in processed_tiles):\n",
    "        missing_tiles.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=9291758365-jcrgrd0a3gfv10ipqfc5vq675ua5hve4.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the actual generation and export of tiles\n",
    "* Important: copy the ID of your google-folder as a string into the the variable 'drive_list' (is highlighted slightly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=9291758365-jcrgrd0a3gfv10ipqfc5vq675ua5hve4.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=9291758365-jcrgrd0a3gfv10ipqfc5vq675ua5hve4.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=9291758365-jcrgrd0a3gfv10ipqfc5vq675ua5hve4.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=9291758365-jcrgrd0a3gfv10ipqfc5vq675ua5hve4.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "n_tasks = 0\n",
    "\n",
    "for tile in missing_tiles:\n",
    "    while(n_tasks >=15):\n",
    "        time.sleep(60)\n",
    "        try:\n",
    "            task_list = str(ee.batch.Task.list())\n",
    "            n_running = task_list.count('RUNNING')\n",
    "            n_ready = task_list.count('READY')\n",
    "            n_tasks = n_running + n_ready\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "\n",
    "    export_composite(int(tile))\n",
    "    task_list = str(ee.batch.Task.list())\n",
    "    n_running = task_list.count('RUNNING')\n",
    "    n_ready = task_list.count('READY')\n",
    "    n_tasks = n_running + n_ready\n",
    "    #\n",
    "    drive_list = drive.ListFile({'q': \"'0B9hZR9DKK3xRS3phZnhQcVlwVHc' in parents and trashed=false\"}).GetList()\n",
    "    #\n",
    "    for file in drive_list:\n",
    "        file_id = drive.CreateFile({'id': file['id']})\n",
    "        fname = file[\"title\"]\n",
    "        file_id.GetContentFile(localFolder + fname)\n",
    "        file_id.Delete() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
